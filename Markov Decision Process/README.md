A Markov decision process (MDP) refers to a stochastic decision-making process that uses a mathematical framework to model the decision-making of a dynamic system. It is used in scenarios where the results are either random or controlled by a decision maker, which makes sequential decisions over time.


In a Markov Decision Process, there are also 3 important properties that must be satisfied:

The environment is fully observable. This means that all the stations are shown on the Tube map.

The future is just dependent on the present.

The probability to reach the successor state only depends on the current state.
